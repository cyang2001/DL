# Syst√®me de Collecte de Donn√©es pour la Reconnaissance de Langue des Signes

## Description du Projet

Ce projet impl√©mente un syst√®me de collecte de donn√©es pour la reconnaissance de langue des signes utilisant MediaPipe et OpenCV. Il permet de capturer et d'analyser les mouvements corporels, faciaux et des mains pour cr√©er des datasets d'entra√Ænement pour des mod√®les d'apprentissage automatique.

## Architecture du Projet

### Module Utils (`utils.py`)

Le module `utils.py` contient les fonctions utilitaires essentielles pour le traitement des donn√©es MediaPipe :

#### Fonctions Principales

- **`mediapipe_detection(image, model)`** : Effectue la d√©tection MediaPipe sur une image
  - Convertit l'image de BGR vers RGB
  - Traite l'image avec le mod√®le MediaPipe
  - Retourne l'image trait√©e et les r√©sultats de d√©tection

- **`draw_landmarks(image, results)`** : Dessine les points de rep√®re basiques
  - Affiche les connexions faciales (FACEMESH_TESSELATION)
  - Affiche les connexions de pose corporelle
  - Affiche les connexions des mains gauche et droite

- **`draw_styled_landmarks(image, results)`** : Dessine les points de rep√®re avec un style personnalis√©
  - Utilise des couleurs diff√©rentes pour chaque type de landmark
  - Applique des √©paisseurs et rayons personnalis√©s pour une meilleure visualisation

- **`extract_keypoints(results)`** : Extrait les coordonn√©es des points cl√©s
  - **Pose** : 33 points √ó 4 coordonn√©es (x, y, z, visibility) = 132 valeurs
  - **Visage** : 468 points √ó 3 coordonn√©es (x, y, z) = 1404 valeurs
  - **Main gauche** : 21 points √ó 3 coordonn√©es = 63 valeurs
  - **Main droite** : 21 points √ó 3 coordonn√©es = 63 valeurs
  - **Total** : 1662 valeurs par frame

### Module Collection (`collection.py`)

Le module `collection.py` impl√©mente le syst√®me de collecte de donn√©es interactif :

#### Fonctionnalit√©s

- **Collecte Interactive** : Utilisation de la barre d'espace pour d√©marrer/arr√™ter l'enregistrement
- **S√©quences Temporelles** : Capture de 30 frames par s√©quence par d√©faut
- **Gestion Automatique** : Organisation automatique des donn√©es par mot et s√©quence
- **Visualisation en Temps R√©el** : Affichage des landmarks pendant la capture
- **Sauvegarde Structur√©e** : Stockage des donn√©es au format NumPy (.npy)

## Installation et Configuration

### Pr√©requis

- Python 3.10
- Camera fonctionnelle
- Syst√®me d'exploitation compatible avec MediaPipe

### Installation des D√©pendances

```bash
pip install -r requirements.txt
```

### D√©pendances Principales

- **OpenCV** : Traitement d'images et capture vid√©o
- **MediaPipe** : D√©tection et suivi des landmarks corporels
- **NumPy** : Manipulation des donn√©es num√©riques
- **TensorFlow/Keras** : Framework d'apprentissage automatique

## Guide d'Utilisation

### 1. D√©marrage du Mode Collecte

Pour commencer la collecte de donn√©es, ex√©cutez :

```bash
python collection.py
```

### 2. Configuration de la Collecte

Lors du d√©marrage, le syst√®me vous demandera :

```
Please input the word you want to capture(e.g. hello):
```

Saisissez le mot ou geste que vous souhaitez enregistrer (par exemple : "bonjour", "merci", "au_revoir").

### 3. Processus de Collecte

#### Interface de Collecte

1. **Fen√™tre de Pr√©visualisation** : Une fen√™tre OpenCV s'ouvre montrant :
   - Le flux vid√©o en temps r√©el
   - Les landmarks MediaPipe superpos√©s
   - L'√©tat d'enregistrement actuel

2. **Contr√¥les Clavier** :
   - **Barre d'espace** : D√©marrer/arr√™ter l'enregistrement d'une s√©quence
   - **√âchap** : Fermer l'application (dans la fen√™tre OpenCV)

#### Workflow de Collecte

1. **Positionnement** : Placez-vous devant la cam√©ra
2. **Pr√©paration** : Pr√©parez le geste √† enregistrer
3. **D√©marrage** : Appuyez sur la barre d'espace pour commencer
4. **Ex√©cution** : Effectuez le geste (30 frames seront captur√©es)
5. **Arr√™t** : Appuyez √† nouveau sur la barre d'espace ou attendez la capture automatique
6. **R√©p√©tition** : Le processus se r√©p√®te pour 10 s√©quences par d√©faut

### 4. Structure des Donn√©es G√©n√©r√©es

```
MP_Data/
‚îî‚îÄ‚îÄ [nom_du_mot]/
    ‚îú‚îÄ‚îÄ 0/
    ‚îÇ   ‚îú‚îÄ‚îÄ 0.npy
    ‚îÇ   ‚îú‚îÄ‚îÄ 1.npy
    ‚îÇ   ‚îî‚îÄ‚îÄ ... (jusqu'√† 29.npy)
    ‚îú‚îÄ‚îÄ 1/
    ‚îÇ   ‚îú‚îÄ‚îÄ 0.npy
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ ... (jusqu'√† 9/)
```

Chaque fichier `.npy` contient un vecteur de 1662 valeurs repr√©sentant tous les landmarks d'une frame.

### 5. Param√®tres Configurables

Dans `collection.py`, vous pouvez modifier :

```python
SEQUENCE_LENGTH = 30    # Nombre de frames par s√©quence
CAPTURE_TIMES = 10      # Nombre de s√©quences √† capturer
DATA_PATH = 'MP_Data'   # R√©pertoire de sauvegarde
```

## Conseils d'Utilisation

### Pour une Collecte Optimale

1. **√âclairage** : Assurez-vous d'avoir un bon √©clairage
2. **Arri√®re-plan** : Utilisez un arri√®re-plan contrast√© et uniforme
3. **Position** : Restez √† une distance appropri√©e de la cam√©ra (1-2 m√®tres)
4. **Stabilit√©** : √âvitez les mouvements brusques de la cam√©ra
5. **Coh√©rence** : Maintenez une vitesse d'ex√©cution constante pour chaque geste

### Gestion des Erreurs

- **Cam√©ra non d√©tect√©e** : V√©rifiez que votre webcam est connect√©e et fonctionnelle
- **Landmarks non d√©tect√©s** : Am√©liorez l'√©clairage ou ajustez votre position
- **Erreurs de sauvegarde** : V√©rifiez les permissions d'√©criture dans le r√©pertoire

## D√©veloppement Futur

Ce syst√®me de collecte peut √™tre √©tendu pour :

- Int√©gration avec des mod√®les de classification en temps r√©el
- Support de gestes plus complexes
- Interface graphique am√©lior√©e
- Collecte de donn√©es multi-utilisateurs
- Validation automatique de la qualit√© des donn√©es

## Support Technique

Pour toute question ou probl√®me technique, merci de commniquer avec Chen YANG sur WhatsAPP ou Teams

---

# Hand Sign Language Recognition - Preprocessing Module

This project implements a comprehensive preprocessing pipeline for hand sign language recognition using MediaPipe and deep learning.

## Project Structure and Working Directory

**IMPORTANT**: Always run scripts from the **project root directory** to avoid path issues!

```
project_root/                     ‚Üê Run all scripts from here
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ classification/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ classifier.py          # LSTM with attention classifier
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing/             # (ToDo)
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ data_preprocessor.py   
‚îÇ       ‚îú‚îÄ‚îÄ data_augmentor.py      
‚îÇ       ‚îú‚îÄ‚îÄ feature_engineer.py   
‚îÇ       ‚îî‚îÄ‚îÄ preprocessing_pipeline.py  
‚îú‚îÄ‚îÄ utils.py                       
‚îú‚îÄ‚îÄ collection.py                  
‚îú‚îÄ‚îÄ demo_preprocessing.py          
‚îú‚îÄ‚îÄ check_project_setup.py         
‚îú‚îÄ‚îÄ requirements.txt               
‚îú‚îÄ‚îÄ MP_data/                       
‚îî‚îÄ‚îÄ processed_data/                
```

### Path Resolution

The preprocessing pipeline automatically resolves all paths relative to the project root directory by:
1. Finding the directory containing `utils.py` (project root marker)
2. Converting relative paths to absolute paths based on project root
3. Logging resolved paths for verification

## Quick Setup Verification

üõ†Ô∏è **Before starting, verify your setup**:

```bash
# Check if you're in the right directory and everything is set up correctly
python check_project_setup.py
```

This script will:
- Check if you're in the project root directory
- Verify all required files and directories exist
- Test imports to ensure everything works
- Provide guidance if something is wrong

## Data Structure

The system works with MediaPipe hand sign language data:
- **Sequence Length**: 30 frames
- **Feature Dimension**: 1662 features per frame
  - Pose: 132 features (33 points √ó 4: x,y,z,visibility)
  - Face: 1404 features (468 points √ó 3: x,y,z)
  - Left Hand: 63 features (21 points √ó 3: x,y,z)
  - Right Hand: 63 features (21 points √ó 3: x,y,z)

## Installation

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Verify setup:
```bash
python check_project_setup.py
```

3. Make sure you have collected data using `collection.py` first:
```bash
python collection.py
```

## Usage

### Quick Start - Demo

Run the preprocessing demo to see how the modules work:

```bash
# Make sure you're in the project root directory
python demo_preprocessing.py
```

### Working Directory Guidelines

 **Correct way**:
```bash
# From project root
python check_project_setup.py
python demo_preprocessing.py
python collection.py
```

**Wrong way**:
```bash
# From subdirectories
cd src/preprocessing/
python ../../demo_preprocessing.py  # This will cause path issues
```

### Using Individual Components

#### 1. Data Preprocessor

```python
from src.preprocessing import DataPreprocessor

config = {
    "sequence_length": 30,
    "feature_dim": 1662,
    "enable_normalization": True,
    "normalization_method": "standard",
    "enable_smoothing": True,
    "enable_interpolation": True,
    "max_zero_ratio": 0.3
}

preprocessor = DataPreprocessor(config)

# Load and process data for a specific word
sequences, info = preprocessor.load_sequence_data("MP_data", "hello")

# Clean individual sequences
cleaned_sequence = preprocessor.clean_sequence(sequence)

# Process entire dataset
processed_data = preprocessor.process_dataset("MP_data", ["hello", "world"])
```

#### 2. Data Augmentor

```python
from src.preprocessing import DataAugmentor

config = {
    "enable_augmentation": True,
    "augmentation_probability": 0.5,
    "enable_noise": True,
    "noise_std": 0.01,
    "enable_time_warping": True,
    "enable_spatial_transform": True
}

augmentor = DataAugmentor(config)

# Augment single sequence
augmented_sequence = augmentor.augment_sequence(sequence)

# Augment entire dataset
augmented_X, augmented_y = augmentor.augment_dataset(X_train, y_train, augmentation_factor=2)
```

#### 3. Feature Engineer

```python
from src.preprocessing import FeatureEngineer

config = {
    "enable_feature_engineering": True,
    "extract_velocity": True,
    "extract_acceleration": True,
    "extract_angles": True,
    "extract_distances": True
}

feature_engineer = FeatureEngineer(config)

# Extract advanced features from sequence
enhanced_sequence = feature_engineer.extract_features(sequence)
```

#### 4. Complete Pipeline

```python
from src.preprocessing import PreprocessingPipeline

config = {
    "raw_data_path": "MP_data",           # Relative to project root
    "processed_data_path": "processed_data",  # Relative to project root
    "validation_split": 0.2,
    "test_split": 0.1,
    "preprocessing": {
        "enable_normalization": True,
        "normalization_method": "standard"
    },
    "augmentation": {
        "enable_augmentation": True,
        "augmentation_factor": 2
    },
    "feature_engineering": {
        "enable_feature_engineering": False
    }
}

pipeline = PreprocessingPipeline(config)

# Process complete dataset
words = ["hello", "world", "thank", "you"]
result = pipeline.process_full_pipeline(words, save_processed=True)

# Access processed data
X_train, y_train = result["X_train"], result["y_train"]
X_val, y_val = result["X_val"], result["y_val"]
X_test, y_test = result["X_test"], result["y_test"]
```

## Todo List

The preprocessing modules contain function signatures and documentation and you have to implement the following:

### DataPreprocessor (src/preprocessing/data_preprocessor.py)

- [ ] `load_sequence_data()`: Load sequences from file system
- [ ] `validate_sequence()`: Check data quality and detect issues
- [ ] `_detect_outliers()`: Implement outlier detection using z-score
- [ ] `clean_sequence()`: Clean data by handling missing values
- [ ] `_interpolate_missing_values()`: Fill missing values using interpolation
- [ ] `_smooth_sequence()`: Apply smoothing filters to reduce noise
- [ ] `normalize_sequences()`: Normalize data using StandardScaler or MinMaxScaler
- [ ] `process_dataset()`: Complete dataset processing workflow
- [ ] `_save_processed_data()`: Save processed data to disk

### DataAugmentor (src/preprocessing/data_augmentor.py)

- [ ] `augment_sequence()`: Apply augmentation to single sequence
- [ ] `_add_noise()`: Add Gaussian noise to data
- [ ] `_time_warping()`: Implement time warping transformation
- [ ] `_magnitude_warping()`: Apply magnitude warping
- [ ] `_window_slicing()`: Implement window slicing technique
- [ ] `_spatial_transformation()`: Apply spatial transformations (rotation, scale, translation)
- [ ] `_speed_variation()`: Change sequence speed
- [ ] `augment_dataset()`: Augment entire dataset

### FeatureEngineer (src/preprocessing/feature_engineer.py)

- [ ] `extract_features()`: Main feature extraction pipeline
- [ ] `_extract_velocity_features()`: Calculate velocity from position
- [ ] `_extract_acceleration_features()`: Calculate acceleration from velocity
- [ ] `_extract_angle_features()`: Calculate angles between key points
- [ ] `_extract_distance_features()`: Calculate distances between landmarks
- [ ] `_extract_relative_position_features()`: Calculate relative positions
- [ ] `_extract_statistical_features()`: Extract statistical features over windows
- [ ] `_extract_hand_shape_features()`: Extract hand shape descriptors
- [ ] `_extract_hand_orientation_features()`: Calculate hand orientations
- [ ] `_extract_pose_angle_features()`: Extract pose angles
- [ ] `_extract_hand_coordinates()`: Extract hand coordinates from sequence
- [ ] `_calculate_angle()`: Calculate angle between three points

### PreprocessingPipeline (src/preprocessing/preprocessing_pipeline.py)

- [ ] `process_full_pipeline()`: Complete preprocessing workflow
- [ ] `_split_dataset()`: Split data into train/validation/test sets
- [ ] `_compute_final_statistics()`: Calculate dataset statistics
- [ ] `_save_processed_dataset()`: Save complete processed dataset
- [ ] `load_processed_dataset()`: Load previously processed data
- [ ] `preprocess_single_sequence()`: Preprocess single sequence for inference

## Integration with Classifier

After implementing the preprocessing modules, integrate with the existing classifier:

```python
from src.preprocessing import PreprocessingPipeline
from src.classification.classifier import AttentionLSTMClassifier

# Process data
pipeline = PreprocessingPipeline(config)
processed_data = pipeline.process_full_pipeline(words)

# Train classifier
classifier_config = {
    "num_classes": len(words),
    "sequence_length": 30,
    "feature_dim": processed_data["X_train"].shape[2]  # May be enhanced by feature engineering
}

classifier = AttentionLSTMClassifier(classifier_config)
classifier.build_model()

history = classifier.train(
    processed_data["X_train"], processed_data["y_train"],
    processed_data["X_val"], processed_data["y_val"]
)
```

## Data Quality Issues to Address

The current dataset has some quality issues that preprocessing should handle:

1. **Zero Values**: ~3.79% of values are zeros (missing detections)
2. **Data Range**: Values range from -1.18 to 2.58
3. **Missing Frames**: Some sequences may have incomplete data
4. **Noise**: Raw MediaPipe data contains detection noise

The preprocessing pipeline is designed to address these issues through:
- Missing value interpolation
- Outlier detection and handling
- Data smoothing and filtering
- Quality validation and reporting

## Tips for Implementation

1. **Start Simple**: Begin with basic implementations and gradually add complexity
2. **Test Incrementally**: Test each function individually before integrating
3. **Handle Edge Cases**: Consider sequences with all zeros, single frames, etc.
4. **Preserve Data Shape**: Ensure outputs maintain expected dimensions
5. **Log Progress**: Use the provided logger to track processing steps
6. **Validate Results**: Check that processed data improves model performance

## Common Issues and Solutions

1. **Path Errors**: 
   - Always run scripts from project root directory
   - Use the setup checker: `python check_project_setup.py`
   - Don't run from subdirectories

2. **Import Errors**: 
   - Make sure the `src` directory is in your Python path
   - Run from project root directory
   - Verify setup with `python check_project_setup.py`

3. **Missing Data**: 
   - Ensure you've collected data using `collection.py` first
   - Check that `MP_data/` directory exists in project root

4. **Memory Issues**: 
   - Process data in batches for large datasets

5. **Shape Mismatches**: 
   - Carefully track array dimensions throughout pipeline

## Development Workflow

```bash
# 1. Verify setup
python check_project_setup.py

# 2. Collect data first (if not done)
python collection.py

# 3. Test preprocessing demo
python demo_preprocessing.py

# 4. Implement preprocessing functions
# Edit files in src/preprocessing/

# 5. Test individual components
python demo_preprocessing.py

# 6. Integrate with classifier
# Use both preprocessing and classification modules
```

Remember: **Always work from the project root directory!** 